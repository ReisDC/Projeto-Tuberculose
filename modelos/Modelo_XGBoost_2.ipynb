{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "368d9d72-dc79-46e7-bce2-60fccebf6b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline # <-- USAR Pipeline do sklearn AGORA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.utils.class_weight import compute_class_weight # <-- Importar para calcular pesos\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3fd96fa-6f8d-4ea3-8ea8-7547e9a52a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Carregar e Preprocessar Dados (mantido como está) ---\n",
    "df = pd.read_csv('/mnt/c/Users/AcerGamer/Downloads/Tuberculose/Projeto-Tuberculose/dados/arquivos_csv/dados_tuberculose_transformados.csv',low_memory=False, encoding='latin1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d93ccf61-27dd-4c53-9f4c-63f1ea0d5625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Debug da Coluna 'FORMA' ---\n",
      "Valores únicos em 'FORMA' ANTES do mapeamento: [ 1.  2.  3. nan]\n",
      "Contagem de nulos em 'FORMA' ANTES do mapeamento: 188\n"
     ]
    }
   ],
   "source": [
    "# --- ETAPAS DE DEBUG PARA COLUNA 'FORMA' ---\n",
    "print(\"--- Debug da Coluna 'FORMA' ---\")\n",
    "print(f\"Valores únicos em 'FORMA' ANTES do mapeamento: {df['FORMA'].unique()}\")\n",
    "print(f\"Contagem de nulos em 'FORMA' ANTES do mapeamento: {df['FORMA'].isnull().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c11592b-690b-4043-831a-af20d2a0521d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeamento do atributo 'FORMA' para os valores numéricos esperados\n",
    "# Certifique-se de que este mapeamento está correto para seus dados\n",
    "df['FORMA'] = df['FORMA'].map({\n",
    "    'PULMONAR': 1.0,\n",
    "    'EXTRAPULMONAR': 2.0,\n",
    "    'MISTA': 3.0\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4636c863-dbf2-4bf3-95b8-95d902b06678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos em 'FORMA' APÓS o mapeamento: [nan]\n",
      "Contagem de nulos em 'FORMA' APÓS o mapeamento: 502271\n"
     ]
    }
   ],
   "source": [
    "print(f\"Valores únicos em 'FORMA' APÓS o mapeamento: {df['FORMA'].unique()}\")\n",
    "print(f\"Contagem de nulos em 'FORMA' APÓS o mapeamento: {df['FORMA'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43e17a47-c3df-4686-a29e-6d3b925a4611",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['FORMA'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "690c0f1b-823a-41e1-970e-238dcb78b52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos em 'FORMA' APÓS dropna: []\n",
      "Contagem de nulos em 'FORMA' APÓS dropna: 0\n",
      "--- Fim do Debug da Coluna 'FORMA' ---\n"
     ]
    }
   ],
   "source": [
    "print(f\"Valores únicos em 'FORMA' APÓS dropna: {df['FORMA'].unique()}\")\n",
    "print(f\"Contagem de nulos em 'FORMA' APÓS dropna: {df['FORMA'].isnull().sum()}\")\n",
    "print(\"--- Fim do Debug da Coluna 'FORMA' ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7cbe9bd-ccab-43fb-a513-adab72012e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ADIÇÃO CRÍTICA: TRATAMENTO DE TIPOS E REMOÇÃO DE COLUNAS COM MUITOS NULOS ---\n",
    "\n",
    "# 1. Lista de colunas com ALTÍSSIMA porcentagem de valores nulos (mais de 90-95%)\n",
    "# Estas colunas raramente contribuem e podem ser removidas para simplificar\n",
    "cols_to_drop_high_nulls = [\n",
    "    'DT_TRANSRM', 'CS_FLXRET', 'FLXRECEBI', 'MIGRADO_W', 'ID_OCUPA_N',\n",
    "    'TESTE_TUBE', 'BACILOS_E2', 'RIFAMPICIN', 'ISONIAZIDA', 'ETAMBUTOL',\n",
    "    'ESTREPTOMI', 'PIRAZINAMI', 'ETIONAMIDA', 'OUTRAS', 'OUTRAS_DES',\n",
    "    'TRAT_SUPER', 'DOENCA_TRA', 'DT_MUDANCA', 'SITUA_9_M', 'SITUA_12_M',\n",
    "    'TRANSF', 'UF_TRANSF', 'MUN_TRANSF'\n",
    "]\n",
    "# Remover estas colunas do DataFrame\n",
    "df = df.drop(columns=[col for col in cols_to_drop_high_nulls if col in df.columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f083a34-eed7-4f90-bcc5-265f7cb974f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Lista de colunas que são CATEGÓRICAS (incluindo as que são float mas representam códigos)\n",
    "# Estas colunas serão explicitamente convertidas para string para o OneHotEncoder\n",
    "categorical_cols_for_conversion = [\n",
    "    'ID_AGRAVO', 'CS_SEXO', 'CS_GESTANT', 'CS_RACA', 'CS_ESCOL_N',\n",
    "    'RAIOX_TORA', 'BACILOSC_E', 'CULTURA_ES', 'HIV', 'HISTOPATOL',\n",
    "    'EXTRAPU1_N', 'EXTRAPU2_N', 'EXTRAPUL_O', 'AGRAVOUTRA', 'AGRAVOUTDE',\n",
    "    'BACILOSC_O', 'CULTURA_OU', 'SG_UF_AT', 'BACILOSC_1', 'BACILOSC_2',\n",
    "    'BACILOSC_3', 'BACILOSC_4', 'BACILOSC_5', 'BACILOSC_6',\n",
    "    'TEST_SENSI', 'ANT_RETRO', 'BAC_APOS_6', 'BENEF_GOV',\n",
    "    'TP_NOT', 'NU_ANO', 'SG_UF_NOT', 'ID_MUNICIP', 'ID_REGIONA',\n",
    "    'ID_MN_RESI', 'ID_RG_RESI', 'ID_PAIS', 'TRATAMENTO', 'INSTITUCIO',\n",
    "    'AGRAVAIDS', 'AGRAVALCOO', 'AGRAVDIABE', 'AGRAVDOENC', 'AGRAVDROGA', 'AGRAVTABAC',\n",
    "    'TEST_MOLEC', 'NU_CONTATO', 'TRATSUP_AT', 'SITUA_ENCE', 'TPUNINOT',\n",
    "    'POP_LIBER', 'POP_RUA', 'POP_SAUDE', 'POP_IMIG'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb0639b6-ea21-47c4-9e1b-39f5b13760bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter essas colunas para tipo string. np.nan se tornará 'nan' (string)\n",
    "for col in categorical_cols_for_conversion:\n",
    "    if col in df.columns: # Verifica se a coluna não foi removida no passo anterior\n",
    "        df[col] = df[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2183ea8e-9606-4429-9c7a-adca7d4e1a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar features (X) e target (y)\n",
    "X = df.drop('FORMA', axis=1)\n",
    "y = df['FORMA']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "234b33a6-0fcc-42df-9329-35226e241c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos em 'FORMA' (target) antes do LabelEncoder: []\n"
     ]
    }
   ],
   "source": [
    "print(f\"Valores únicos em 'FORMA' (target) antes do LabelEncoder: {y.unique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e24a6dd-3af2-4cc3-91d8-9bdd58cd1207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar a variável target 'y' (seus rótulos numéricos para 0, 1, 2)\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y) # Agora y_encoded terá 0, 1, 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e547499-4e67-4b99-bd91-99f4ee7a355a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapeamento do LabelEncoder (ID Original -> Código Interno):\n"
     ]
    }
   ],
   "source": [
    "# Exibir mapeamento do LabelEncoder\n",
    "print(\"Mapeamento do LabelEncoder (ID Original -> Código Interno):\")\n",
    "for original_id, encoded_value in zip(le.classes_, le.transform(le.classes_)):\n",
    "    print(f\"ID Original {original_id} -> Código Interno {encoded_value}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3428c920-197a-4947-8750-9cef3d761ede",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Divisão em treino e teste (mantido como está)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m X_train, X_test, y_train, y_test = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstratify\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_encoded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Identificar colunas numéricas e categóricas (mantido como está)\u001b[39;00m\n\u001b[32m      5\u001b[39m numeric_features = X.select_dtypes(include=np.number).columns.tolist()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter_env/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter_env/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2851\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2848\u001b[39m arrays = indexable(*arrays)\n\u001b[32m   2850\u001b[39m n_samples = _num_samples(arrays[\u001b[32m0\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m2851\u001b[39m n_train, n_test = \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2852\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.25\u001b[39;49m\n\u001b[32m   2853\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2855\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m   2856\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter_env/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2481\u001b[39m, in \u001b[36m_validate_shuffle_split\u001b[39m\u001b[34m(n_samples, test_size, train_size, default_test_size)\u001b[39m\n\u001b[32m   2478\u001b[39m n_train, n_test = \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[32m   2480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_train == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2481\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2482\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2483\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2484\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33maforementioned parameters.\u001b[39m\u001b[33m\"\u001b[39m.format(n_samples, test_size, train_size)\n\u001b[32m   2485\u001b[39m     )\n\u001b[32m   2487\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[31mValueError\u001b[39m: With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "# Divisão em treino e teste (mantido como está)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded)\n",
    "\n",
    "# Identificar colunas numéricas e categóricas (mantido como está)\n",
    "numeric_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include='object').columns.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffaf70b-6e9d-479a-b2c4-2ea6c8780ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento (mantido como está)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', SimpleImputer(strategy='mean'), numeric_features),\n",
    "        ('cat', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), categorical_features)\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c438d723-9b12-404b-abf4-08a93fd09dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Calcular Pesos de Classe ---\n",
    "# Contagem de classes em y_train (para referência e confirmação)\n",
    "print(\"\\nContagem de classes em y_train (códigos internos):\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f920ca2f-7ece-44cf-a682-8f6310b36a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcule os pesos das classes para lidar com o desbalanceamento\n",
    "# 'balanced' ajusta os pesos inversamente proporcionais às frequências das classes\n",
    "classes = np.unique(y_train) # 0, 1, 2\n",
    "class_weights_array = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=classes,\n",
    "    y=y_train\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48450106-a0a6-441e-8960-dce0418be822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie um dicionário de mapeamento código interno -> peso\n",
    "class_weights = dict(zip(classes, class_weights_array))\n",
    "\n",
    "print(\"\\nPesos de classe calculados:\")\n",
    "for code, weight in class_weights.items():\n",
    "    original_id = le.inverse_transform([code])[0]\n",
    "    print(f\"Classe Original {original_id} (Código Interno {code}): Peso = {weight:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d1182f-5796-4c0f-8634-97685b0b3716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie um array de pesos para cada amostra no y_train\n",
    "# Cada amostra receberá o peso correspondente à sua classe\n",
    "sample_weights_train = np.array([class_weights[label] for label in y_train])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b409c48-1f73-4873-acdb-18f65ab15fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Construção do Pipeline ---\n",
    "#pipeline_final = Pipeline(steps=[ # <--- ATENÇÃO: Agora é sklearn.pipeline.Pipeline\n",
    "#    ('preprocessor', preprocessor),\n",
    "#    ('selector', SelectFromModel(XGBClassifier(n_estimators=50, random_state=42, use_label_encoder=False, eval_metric='mlogloss'))),\n",
    "#    ('classifier', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss', tree_method='hist'))\n",
    "#])\n",
    "# --- 3. Construção do Pipeline ---\n",
    "num_classes = len(np.unique(y_encoded)) # Obter o número de classes\n",
    "\n",
    "pipeline_final = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', SelectFromModel(XGBClassifier(\n",
    "        n_estimators=50,\n",
    "        random_state=42,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='mlogloss',\n",
    "        objective='multi:softprob', # Definido explicitamente\n",
    "        num_class=num_classes # Definido explicitamente\n",
    "    ))),\n",
    "    ('classifier', XGBClassifier(\n",
    "        random_state=42,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='mlogloss',\n",
    "        tree_method='hist',\n",
    "        objective='multi:softprob', # Definido explicitamente\n",
    "        num_class=num_classes # Definido explicitamente\n",
    "    ))\n",
    "])\n",
    "\n",
    "print(\"\\nIniciando o treinamento do pipeline com XGBoost e pesos de classe...\")\n",
    "pipeline_final.fit(X_train, y_train, classifier__sample_weight=sample_weights_train)\n",
    "print(\"Treinamento concluído com pesos de classe.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde819a8-e448-457d-a70c-7eb249d7423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nIniciando o treinamento do pipeline com XGBoost e pesos de classe...\")\n",
    "# Passar os pesos das amostras para o estimador final (classifier) no pipeline\n",
    "pipeline_final.fit(X_train, y_train, classifier__sample_weight=sample_weights_train) # <--- AQUI A MUDANÇA CRÍTICA\n",
    "print(\"Treinamento concluído com pesos de classe.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39661db2-746b-4a52-8f10-ee675c4d58c7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# --- 4. Avaliação do Modelo (mantido como está) ---\n",
    "y_pred = pipeline_final.predict(X_test)\n",
    "\n",
    "# Mapear as previsões e os valores reais de volta para os nomes descritivos\n",
    "mapeamento_nomes_descritivos = {\n",
    "    1.0: \"Pulmonar\",\n",
    "    2.0: \"Extrapulmonar\",\n",
    "    3.0: \"Mista\"\n",
    "}\n",
    "\n",
    "y_pred_original_ids = le.inverse_transform(y_pred)\n",
    "y_test_original_ids = le.inverse_transform(y_test)\n",
    "\n",
    "y_pred_nomes = [mapeamento_nomes_descritivos[idx] for idx in y_pred_original_ids]\n",
    "y_test_nomes = [mapeamento_nomes_descritivos[idx] for idx in y_test_original_ids]\n",
    "\n",
    "# Definir a ordem exata das classes para exibição (Pulmonar, Extrapulmonar, Mista)\n",
    "class_display_order = [\"Pulmonar\", \"Extrapulmonar\", \"Mista\"] # Certifique-se de que esta é a ordem que você quer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569d7e1d-89c2-4e38-9e08-97d92ab441d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Avaliação do Modelo ---\n",
    "y_pred = pipeline_final.predict(X_test)\n",
    "\n",
    "mapeamento_nomes_descritivos = {\n",
    "    1.0: \"Pulmonar\",\n",
    "    2.0: \"Extrapulmonar\",\n",
    "    3.0: \"Mista\"\n",
    "}\n",
    "\n",
    "y_pred_original_ids = le.inverse_transform(y_pred)\n",
    "y_test_original_ids = le.inverse_transform(y_test)\n",
    "\n",
    "y_pred_nomes = [mapeamento_nomes_descritivos[idx] for idx in y_pred_original_ids]\n",
    "y_test_nomes = [mapeamento_nomes_descritivos[idx] for idx in y_test_original_ids]\n",
    "\n",
    "class_display_order = [\"Pulmonar\", \"Extrapulmonar\", \"Mista\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cf138f-89f3-4e88-b230-f95c8836f7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRelatório de Classificação com Nomes Descritivos (com Pesos de Classe):\")\n",
    "print(classification_report(y_test_nomes, y_pred_nomes, target_names=class_display_order))\n",
    "\n",
    "cm_nomes = confusion_matrix(y_test_nomes, y_pred_nomes, labels=class_display_order)\n",
    "print(\"\\nMatriz de Confusão com Nomes Descritivos (com Pesos de Classe):\")\n",
    "print(cm_nomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bbd398-fb16-4ac4-9aef-9cca49070396",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_nomes, display_labels=class_display_order)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Matriz de Confusão com Pesos de Classe')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796abc93-4cf0-4b55-8eeb-feeba1f32739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8fc886-2c0b-4d87-8f6f-5149632eecbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
